{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ECE470 - Project .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smnmMZeLlpyW"
      },
      "source": [
        "# ECE 470 - Final Project\n",
        "## Group Members: Andy Guevara - V00951198\n",
        "## Handwritten Character Recognition Using Convolutional Neural Networks\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Import required libraries and set up GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvqYQIVjnAoG",
        "outputId": "63c40eff-4524-40eb-cf49-39575fb1b10d"
      },
      "source": [
        "import sys\n",
        "import tensorflow as tf\n",
        "import tensorflow.compat.v2 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau,ModelCheckpoint\n",
        "\n",
        "import tensorflow.compat.v2 as tf\n",
        "\n",
        "import tensorflow_datasets.public_api as tfds\n",
        "\n",
        "print('-'*40)\n",
        "print ('Python version: {}'.format(sys.version))\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------\n",
            "Python version: 3.7.11 (default, Jul  3 2021, 18:01:19) \n",
            "[GCC 7.5.0]\n",
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrlTKbVczthT"
      },
      "source": [
        "Loading EMNIST Dataset from Tensorflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02bf__BFz3X0",
        "outputId": "8b091e8b-37e4-42b6-e5fe-0e9db8d779b7"
      },
      "source": [
        "(emnist_train, emnist_test), ds_info = tfds.load('emnist', \n",
        "                                                 split = ['train', 'test'], \n",
        "                                                 shuffle_files=True, \n",
        "                                                 as_supervised=True, \n",
        "                                                 with_info=True) #change as supervised if examples needed\n",
        "#assert isinstance(emnist_train, tf.data.Dataset)\n",
        "print(ds_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tfds.core.DatasetInfo(\n",
            "    name='emnist',\n",
            "    version=3.0.0,\n",
            "    description='The EMNIST dataset is a set of handwritten character digits derived from the NIST Special Database 19 and converted to a 28x28 pixel image format and dataset structure that directly matches the MNIST dataset.\n",
            "\n",
            "Note: Like the original EMNIST data, images provided here are inverted horizontally and rotated 90 anti-clockwise. You can use `tf.transpose` within `ds.map` to convert the images to a human-friendlier format.',\n",
            "    homepage='https://www.nist.gov/itl/products-and-services/emnist-dataset',\n",
            "    features=FeaturesDict({\n",
            "        'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
            "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=62),\n",
            "    }),\n",
            "    total_num_examples=814255,\n",
            "    splits={\n",
            "        'test': 116323,\n",
            "        'train': 697932,\n",
            "    },\n",
            "    supervised_keys=('image', 'label'),\n",
            "    citation=\"\"\"@article{cohen_afshar_tapson_schaik_2017,\n",
            "        title={EMNIST: Extending MNIST to handwritten letters},\n",
            "        DOI={10.1109/ijcnn.2017.7966217},\n",
            "        journal={2017 International Joint Conference on Neural Networks (IJCNN)},\n",
            "        author={Cohen, Gregory and Afshar, Saeed and Tapson, Jonathan and Schaik, Andre Van},\n",
            "        year={2017}\n",
            "    }\"\"\",\n",
            "    redistribution_info=,\n",
            ")\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srFQj-0fyhEs"
      },
      "source": [
        "Normalize images, and prepare dataloader."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wVpfVvZyjdo"
      },
      "source": [
        "def normalize_img(img, label):\n",
        "  return tf.cast(img, tf.float32)/255.0,label\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "BATCH_SIZE = 64\n",
        "emnist_train = emnist_train.map(normalize_img, num_parallel_calls = AUTOTUNE)\n",
        "emnist_train = emnist_train.cache()\n",
        "emnist_train = emnist_train.shuffle(ds_info.splits['train'].num_examples)\n",
        "emnist_train = emnist_train.batch(BATCH_SIZE)\n",
        "emnist_train = emnist_train.prefetch(AUTOTUNE)\n",
        "\n",
        "emnist_test = emnist_test.map(normalize_img, num_parallel_calls = AUTOTUNE)\n",
        "emnist_test = emnist_test.batch(BATCH_SIZE)\n",
        "emnist_test = emnist_test.cache()\n",
        "emnist_test = emnist_test.prefetch(AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHJFrdN0LuSY"
      },
      "source": [
        "Building, compile and fit model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4eYAU6OsLVD",
        "outputId": "c90f50dd-ffcb-489b-ab8e-456d9f110112"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (5,5), \n",
        "                        input_shape = (28,28,1), activation = 'relu', \n",
        "                        strides = (1,1))) #32 output channels\n",
        "model.add(layers.Conv2D(64, (3,3), activation='relu', strides = (1,1)))\n",
        "\n",
        "model.add(layers.MaxPooling2D(2,2))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512,activation='relu'))\n",
        "model.add(layers.Dense(128,activation='relu'))\n",
        "model.add(layers.Dense(62, activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "model.compile(optimizer = keras.optimizers.Adam(learning_rate = 0.001), \n",
        "              loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True), \n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "MCP = ModelCheckpoint('Best_points.h5',verbose=1,\n",
        "                      save_best_only=True,\n",
        "                      monitor='accuracy',mode='max')\n",
        "ES = EarlyStopping(monitor='accuracy',min_delta=0,\n",
        "                   verbose=0,restore_best_weights = True,\n",
        "                   patience=3,mode='max')\n",
        "RLP = ReduceLROnPlateau(monitor='loss',patience=3,factor=0.2,min_lr=0.0001)\n",
        "\n",
        "history = model.fit(emnist_train, epochs = 45, callbacks=[MCP,ES,RLP])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 24, 24, 32)        832       \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 22, 22, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 11, 11, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 7744)              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 512)               3965440   \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 62)                7998      \n",
            "=================================================================\n",
            "Total params: 4,058,430\n",
            "Trainable params: 4,058,430\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/45\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:4930: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  '\"`sparse_categorical_crossentropy` received `from_logits=True`, but '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10906/10906 [==============================] - 58s 5ms/step - loss: 0.4570 - accuracy: 0.8401\n",
            "\n",
            "Epoch 00001: accuracy improved from -inf to 0.84006, saving model to Best_points.h5\n",
            "Epoch 2/45\n",
            "10906/10906 [==============================] - 58s 5ms/step - loss: 0.3593 - accuracy: 0.8662\n",
            "\n",
            "Epoch 00002: accuracy improved from 0.84006 to 0.86624, saving model to Best_points.h5\n",
            "Epoch 3/45\n",
            "10906/10906 [==============================] - 59s 5ms/step - loss: 0.3277 - accuracy: 0.8750\n",
            "\n",
            "Epoch 00003: accuracy improved from 0.86624 to 0.87500, saving model to Best_points.h5\n",
            "Epoch 4/45\n",
            "10906/10906 [==============================] - 58s 5ms/step - loss: 0.3024 - accuracy: 0.8823\n",
            "\n",
            "Epoch 00004: accuracy improved from 0.87500 to 0.88233, saving model to Best_points.h5\n",
            "Epoch 5/45\n",
            "10906/10906 [==============================] - 58s 5ms/step - loss: 0.2799 - accuracy: 0.8893\n",
            "\n",
            "Epoch 00005: accuracy improved from 0.88233 to 0.88931, saving model to Best_points.h5\n",
            "Epoch 6/45\n",
            "10906/10906 [==============================] - 58s 5ms/step - loss: 0.2599 - accuracy: 0.8966\n",
            "\n",
            "Epoch 00006: accuracy improved from 0.88931 to 0.89660, saving model to Best_points.h5\n",
            "Epoch 7/45\n",
            "10906/10906 [==============================] - 58s 5ms/step - loss: 0.2406 - accuracy: 0.9039\n",
            "\n",
            "Epoch 00007: accuracy improved from 0.89660 to 0.90392, saving model to Best_points.h5\n",
            "Epoch 8/45\n",
            "10906/10906 [==============================] - 58s 5ms/step - loss: 0.2228 - accuracy: 0.9109\n",
            "\n",
            "Epoch 00008: accuracy improved from 0.90392 to 0.91087, saving model to Best_points.h5\n",
            "Epoch 9/45\n",
            "10906/10906 [==============================] - 58s 5ms/step - loss: 0.2054 - accuracy: 0.9177\n",
            "\n",
            "Epoch 00009: accuracy improved from 0.91087 to 0.91767, saving model to Best_points.h5\n",
            "Epoch 10/45\n",
            "10906/10906 [==============================] - 58s 5ms/step - loss: 0.1899 - accuracy: 0.9244\n",
            "\n",
            "Epoch 00010: accuracy improved from 0.91767 to 0.92435, saving model to Best_points.h5\n",
            "Epoch 11/45\n",
            "10906/10906 [==============================] - 58s 5ms/step - loss: 0.1762 - accuracy: 0.9304\n",
            "\n",
            "Epoch 00011: accuracy improved from 0.92435 to 0.93045, saving model to Best_points.h5\n",
            "Epoch 12/45\n",
            "10906/10906 [==============================] - 58s 5ms/step - loss: 0.1646 - accuracy: 0.9354\n",
            "\n",
            "Epoch 00012: accuracy improved from 0.93045 to 0.93537, saving model to Best_points.h5\n",
            "Epoch 13/45\n",
            "10906/10906 [==============================] - 58s 5ms/step - loss: 0.1546 - accuracy: 0.9402\n",
            "\n",
            "Epoch 00013: accuracy improved from 0.93537 to 0.94016, saving model to Best_points.h5\n",
            "Epoch 14/45\n",
            "10906/10906 [==============================] - 59s 5ms/step - loss: 0.1455 - accuracy: 0.9442\n",
            "\n",
            "Epoch 00014: accuracy improved from 0.94016 to 0.94415, saving model to Best_points.h5\n",
            "Epoch 15/45\n",
            "10906/10906 [==============================] - 58s 5ms/step - loss: 0.1366 - accuracy: 0.9479\n",
            "\n",
            "Epoch 00015: accuracy improved from 0.94415 to 0.94785, saving model to Best_points.h5\n",
            "Epoch 16/45\n",
            "10906/10906 [==============================] - 58s 5ms/step - loss: 0.1298 - accuracy: 0.9508\n",
            "\n",
            "Epoch 00016: accuracy improved from 0.94785 to 0.95082, saving model to Best_points.h5\n",
            "Epoch 17/45\n",
            "10906/10906 [==============================] - 58s 5ms/step - loss: 0.1236 - accuracy: 0.9538\n",
            "\n",
            "Epoch 00017: accuracy improved from 0.95082 to 0.95382, saving model to Best_points.h5\n",
            "Epoch 18/45\n",
            "10906/10906 [==============================] - 58s 5ms/step - loss: 0.1172 - accuracy: 0.9564\n",
            "\n",
            "Epoch 00018: accuracy improved from 0.95382 to 0.95644, saving model to Best_points.h5\n",
            "Epoch 19/45\n",
            "10906/10906 [==============================] - 58s 5ms/step - loss: 0.1140 - accuracy: 0.9585\n",
            "\n",
            "Epoch 00019: accuracy improved from 0.95644 to 0.95854, saving model to Best_points.h5\n",
            "Epoch 20/45\n",
            "10906/10906 [==============================] - 59s 5ms/step - loss: 0.1087 - accuracy: 0.9605\n",
            "\n",
            "Epoch 00020: accuracy improved from 0.95854 to 0.96051, saving model to Best_points.h5\n",
            "Epoch 21/45\n",
            "10906/10906 [==============================] - 58s 5ms/step - loss: 0.1056 - accuracy: 0.9625\n",
            "\n",
            "Epoch 00021: accuracy improved from 0.96051 to 0.96247, saving model to Best_points.h5\n",
            "Epoch 22/45\n",
            "10906/10906 [==============================] - 58s 5ms/step - loss: 0.1013 - accuracy: 0.9643\n",
            "\n",
            "Epoch 00022: accuracy improved from 0.96247 to 0.96425, saving model to Best_points.h5\n",
            "Epoch 23/45\n",
            "10906/10906 [==============================] - 58s 5ms/step - loss: 0.0984 - accuracy: 0.9658\n",
            "\n",
            "Epoch 00023: accuracy improved from 0.96425 to 0.96584, saving model to Best_points.h5\n",
            "Epoch 24/45\n",
            "10906/10906 [==============================] - 58s 5ms/step - loss: 0.0945 - accuracy: 0.9674\n",
            "\n",
            "Epoch 00024: accuracy improved from 0.96584 to 0.96744, saving model to Best_points.h5\n",
            "Epoch 25/45\n",
            "10906/10906 [==============================] - 59s 5ms/step - loss: 0.0908 - accuracy: 0.9690\n",
            "\n",
            "Epoch 00025: accuracy improved from 0.96744 to 0.96900, saving model to Best_points.h5\n",
            "Epoch 26/45\n",
            "10906/10906 [==============================] - 58s 5ms/step - loss: 0.0890 - accuracy: 0.9701\n",
            "\n",
            "Epoch 00026: accuracy improved from 0.96900 to 0.97006, saving model to Best_points.h5\n",
            "Epoch 27/45\n",
            "10906/10906 [==============================] - 59s 5ms/step - loss: 0.0867 - accuracy: 0.9711\n",
            "\n",
            "Epoch 00027: accuracy improved from 0.97006 to 0.97107, saving model to Best_points.h5\n",
            "Epoch 28/45\n",
            "10906/10906 [==============================] - 58s 5ms/step - loss: 0.0848 - accuracy: 0.9723\n",
            "\n",
            "Epoch 00028: accuracy improved from 0.97107 to 0.97228, saving model to Best_points.h5\n",
            "Epoch 29/45\n",
            "10906/10906 [==============================] - 58s 5ms/step - loss: 0.0822 - accuracy: 0.9733\n",
            "\n",
            "Epoch 00029: accuracy improved from 0.97228 to 0.97334, saving model to Best_points.h5\n",
            "Epoch 30/45\n",
            "10906/10906 [==============================] - 59s 5ms/step - loss: 0.0816 - accuracy: 0.9741\n",
            "\n",
            "Epoch 00030: accuracy improved from 0.97334 to 0.97407, saving model to Best_points.h5\n",
            "Epoch 31/45\n",
            "10906/10906 [==============================] - 58s 5ms/step - loss: 0.0803 - accuracy: 0.9748\n",
            "\n",
            "Epoch 00031: accuracy improved from 0.97407 to 0.97484, saving model to Best_points.h5\n",
            "Epoch 32/45\n",
            "10906/10906 [==============================] - 58s 5ms/step - loss: 0.0784 - accuracy: 0.9756\n",
            "\n",
            "Epoch 00032: accuracy improved from 0.97484 to 0.97559, saving model to Best_points.h5\n",
            "Epoch 33/45\n",
            "10906/10906 [==============================] - 58s 5ms/step - loss: 0.0771 - accuracy: 0.9764\n",
            "\n",
            "Epoch 00033: accuracy improved from 0.97559 to 0.97641, saving model to Best_points.h5\n",
            "Epoch 34/45\n",
            "10906/10906 [==============================] - 58s 5ms/step - loss: 0.0764 - accuracy: 0.9768\n",
            "\n",
            "Epoch 00034: accuracy improved from 0.97641 to 0.97680, saving model to Best_points.h5\n",
            "Epoch 35/45\n",
            "10906/10906 [==============================] - 58s 5ms/step - loss: 0.0748 - accuracy: 0.9775\n",
            "\n",
            "Epoch 00035: accuracy improved from 0.97680 to 0.97746, saving model to Best_points.h5\n",
            "Epoch 36/45\n",
            "10906/10906 [==============================] - 59s 5ms/step - loss: 0.0729 - accuracy: 0.9784\n",
            "\n",
            "Epoch 00036: accuracy improved from 0.97746 to 0.97841, saving model to Best_points.h5\n",
            "Epoch 37/45\n",
            "10906/10906 [==============================] - 59s 5ms/step - loss: 0.0744 - accuracy: 0.9785\n",
            "\n",
            "Epoch 00037: accuracy improved from 0.97841 to 0.97852, saving model to Best_points.h5\n",
            "Epoch 38/45\n",
            "10906/10906 [==============================] - 59s 5ms/step - loss: 0.0722 - accuracy: 0.9793\n",
            "\n",
            "Epoch 00038: accuracy improved from 0.97852 to 0.97932, saving model to Best_points.h5\n",
            "Epoch 39/45\n",
            "10906/10906 [==============================] - 59s 5ms/step - loss: 0.0714 - accuracy: 0.9797\n",
            "\n",
            "Epoch 00039: accuracy improved from 0.97932 to 0.97967, saving model to Best_points.h5\n",
            "Epoch 40/45\n",
            "10906/10906 [==============================] - 59s 5ms/step - loss: 0.0706 - accuracy: 0.9805\n",
            "\n",
            "Epoch 00040: accuracy improved from 0.97967 to 0.98046, saving model to Best_points.h5\n",
            "Epoch 41/45\n",
            "10906/10906 [==============================] - 58s 5ms/step - loss: 0.0697 - accuracy: 0.9808\n",
            "\n",
            "Epoch 00041: accuracy improved from 0.98046 to 0.98080, saving model to Best_points.h5\n",
            "Epoch 42/45\n",
            "10906/10906 [==============================] - 59s 5ms/step - loss: 0.0721 - accuracy: 0.9806\n",
            "\n",
            "Epoch 00042: accuracy did not improve from 0.98080\n",
            "Epoch 43/45\n",
            "10906/10906 [==============================] - 59s 5ms/step - loss: 0.0706 - accuracy: 0.9812\n",
            "\n",
            "Epoch 00043: accuracy improved from 0.98080 to 0.98122, saving model to Best_points.h5\n",
            "Epoch 44/45\n",
            "10906/10906 [==============================] - 59s 5ms/step - loss: 0.0664 - accuracy: 0.9820\n",
            "\n",
            "Epoch 00044: accuracy improved from 0.98122 to 0.98203, saving model to Best_points.h5\n",
            "Epoch 45/45\n",
            "10906/10906 [==============================] - 59s 5ms/step - loss: 0.0688 - accuracy: 0.9822\n",
            "\n",
            "Epoch 00045: accuracy improved from 0.98203 to 0.98216, saving model to Best_points.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwgqM30nL2KY"
      },
      "source": [
        "Evaluate model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPJIpcHewfzH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "639d0253-afa0-48dd-bf15-1a72120b52b2"
      },
      "source": [
        "model.evaluate(emnist_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  37/1818 [..............................] - ETA: 5s - loss: 2.8938 - accuracy: 0.8433"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:4930: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  '\"`sparse_categorical_crossentropy` received `from_logits=True`, but '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1818/1818 [==============================] - 5s 3ms/step - loss: 2.9877 - accuracy: 0.8400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.987718105316162, 0.8399542570114136]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVvfxLnb3wVU"
      },
      "source": [
        "Display training results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "spxJqS2q25Xr",
        "outputId": "f81c4463-eb5e-40fd-c79a-6fb34861f4fd"
      },
      "source": [
        "q = len(history.history['accuracy'])\n",
        "\n",
        "plt.figsize=(10,10)\n",
        "sns.lineplot(x = range(1,1+q),y = history.history['accuracy'], label='Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Accuracy')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}